name: Kaggle Notebook Executor

on:
  workflow_dispatch:
  repository_dispatch:
    types: [cron-trigger]

jobs:
  execute-notebooks:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install kaggle
    
    - name: Execute notebooks
      run: |
        python << 'PYEOF'
        import os
        import subprocess
        import json
        import sys
        from datetime import datetime
        from pathlib import Path
        import shutil
        import time

        SOURCE_ACCOUNT = {
            "username": "shreevathsbbhh",
            "key": "83a92caa96ed51b5d5a9a730100c57aa"
        }

        DEST_ACCOUNTS = {
            "vathsamm": {
                "username": "vathsamm",
                "key": "33fad3a4dc6d92aa70fa90b62b9ebef4"
            }
        }

        # 2 NOTEBOOKS â†’ vathsamm
        NOTEBOOKS = [
            {
                "source_slug": "shreevathsbbhh/long-google-tts-8", 
                "notebook_name": "long-google-tts-8", 
                "dest_slug": "vathsamm/long-google-tts-8",
                "dest_account": "vathsamm"
            },
            {
                "source_slug": "shreevathsbbhh/king-main-17", 
                "notebook_name": "king-main-17", 
                "dest_slug": "vathsamm/king-main-17",
                "dest_account": "vathsamm"
            }
        ]

        def log(msg, symbol="â„¹ï¸"):
            timestamp = datetime.utcnow().strftime('%H:%M:%S')
            print(f"[{timestamp}] {symbol} {msg}")
            sys.stdout.flush()

        def setup_kaggle_auth(account):
            kaggle_dir = Path.home() / ".kaggle"
            kaggle_dir.mkdir(exist_ok=True)
            kaggle_json = kaggle_dir / "kaggle.json"
            with open(kaggle_json, 'w') as f:
                json.dump({"username": account["username"], "key": account["key"]}, f)
            kaggle_json.chmod(0o600)
            log(f"Auth set: {account['username']}", "ðŸ”‘")

        def run_cmd(cmd, timeout=180):
            try:
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)
                return result.returncode == 0, result.stdout, result.stderr
            except subprocess.TimeoutExpired:
                return False, "", "Timeout"
            except Exception as e:
                return False, "", str(e)

        def execute_notebook(nb):
            log(f"START: {nb['notebook_name']} â†’ {nb['dest_account']}", "ðŸš€")
            
            source_dir = Path(f"./source_{nb['notebook_name']}")
            dest_dir = Path(f"./dest_{nb['notebook_name']}")
            original_dir = os.getcwd()
            
            try:
                # Clean directories
                for d in [source_dir, dest_dir]:
                    if d.exists():
                        shutil.rmtree(d)
                    d.mkdir()
                
                target_account_key = nb['dest_account']
                dest_account = DEST_ACCOUNTS[target_account_key]
                
                # STEP 1: Pull from DESTINATION first (to get correct id_no and metadata)
                setup_kaggle_auth(dest_account)
                time.sleep(0.3)
                
                log(f"Pulling destination metadata: {nb['dest_slug']}...", "ðŸ“¥")
                success, stdout, stderr = run_cmd(f"kaggle kernels pull {nb['dest_slug']} -p {dest_dir} -m")
                
                dest_exists = success
                if dest_exists:
                    log(f"Destination kernel exists", "âœ…")
                else:
                    log(f"Destination kernel doesn't exist, will create new", "ðŸ†•")
                
                # STEP 2: Pull notebook code from SOURCE
                setup_kaggle_auth(SOURCE_ACCOUNT)
                time.sleep(0.3)
                
                log(f"Pulling source code: {nb['source_slug']}...", "ðŸ“¥")
                success, stdout, stderr = run_cmd(f"kaggle kernels pull {nb['source_slug']} -p {source_dir} -m")
                
                if not success:
                    log(f"SOURCE PULL FAILED: {stderr[:300]}", "âŒ")
                    return False
                
                log(f"Source pull OK", "âœ…")
                
                # Find the notebook file in source
                source_notebooks = list(source_dir.glob("*.ipynb"))
                if not source_notebooks:
                    log(f"No notebook found in source", "âŒ")
                    return False
                
                source_notebook = source_notebooks[0]
                log(f"Source notebook: {source_notebook.name}", "ðŸ“„")
                
                # STEP 3: Prepare final metadata
                if dest_exists:
                    # Use destination's metadata (has correct id_no)
                    dest_metadata_file = dest_dir / "kernel-metadata.json"
                    with open(dest_metadata_file, 'r') as f:
                        metadata = json.load(f)
                    log(f"Using dest metadata: id={metadata.get('id')}, id_no={metadata.get('id_no')}", "ðŸ“")
                    
                    # Copy source notebook to dest directory with correct name
                    dest_notebook_name = metadata.get('code_file', f"{nb['notebook_name']}.ipynb")
                    shutil.copy(source_notebook, dest_dir / dest_notebook_name)
                    
                    # Update code_file reference if needed
                    metadata['code_file'] = dest_notebook_name
                    
                    with open(dest_metadata_file, 'w') as f:
                        json.dump(metadata, f, indent=2)
                    
                    push_dir = dest_dir
                else:
                    # CREATE NEW KERNEL - set id to destination slug
                    source_metadata_file = source_dir / "kernel-metadata.json"
                    with open(source_metadata_file, 'r') as f:
                        metadata = json.load(f)
                    
                    # FIX: Set id to dest_slug (REQUIRED for new kernels)
                    metadata['id'] = nb['dest_slug']
                    metadata.pop('id_no', None)
                    metadata['slug'] = nb['notebook_name']
                    metadata['title'] = nb['notebook_name']
                    metadata['code_file'] = source_notebook.name
                    
                    with open(source_metadata_file, 'w') as f:
                        json.dump(metadata, f, indent=2)
                    
                    log(f"New kernel metadata: id={metadata['id']}, slug={metadata['slug']}", "ðŸ“")
                    push_dir = source_dir
                
                # STEP 4: Push to destination
                setup_kaggle_auth(dest_account)
                time.sleep(0.3)
                
                os.chdir(push_dir)
                log(f"Directory contents: {[f.name for f in Path('.').glob('*')]}", "ðŸ“‚")
                
                log(f"Pushing...", "ðŸ“¤")
                success, stdout, stderr = run_cmd("kaggle kernels push", timeout=240)
                
                os.chdir(original_dir)
                
                if not success:
                    log(f"PUSH FAILED", "âŒ")
                    log(f"Stderr: {stderr}", "")
                    log(f"Stdout: {stdout}", "")
                    return False
                
                log(f"Push OK: {nb['notebook_name']}", "âœ…")
                log(f"URL: https://www.kaggle.com/code/{nb['dest_slug']}", "ðŸ”—")
                return True
                
            except Exception as e:
                log(f"EXCEPTION: {str(e)}", "âŒ")
                import traceback
                traceback.print_exc()
                return False
                
            finally:
                if os.getcwd() != original_dir:
                    os.chdir(original_dir)
                for d in [source_dir, dest_dir]:
                    if d.exists():
                        shutil.rmtree(d, ignore_errors=True)

        def execute_all():
            start = datetime.utcnow()
            log(f"EXECUTION STARTED: {start.isoformat()}", "ðŸš€")
            log(f"Total notebooks: {len(NOTEBOOKS)}", "ðŸ“Š")
            log(f"Destination: vathsamm", "ðŸŽ¯")
            
            results = {}
            
            for nb in NOTEBOOKS:
                log("â•" * 60, "")
                success = execute_notebook(nb)
                results[nb['notebook_name']] = success
            
            success_count = sum(results.values())
            duration = (datetime.utcnow() - start).total_seconds()
            
            log("â•" * 60, "")
            log(f"COMPLETED: {success_count}/{len(results)} | {duration:.1f}s", "ðŸ")
            
            for nb_name, success in results.items():
                log(f"{'âœ…' if success else 'âŒ'} {nb_name}", "")
            
            if success_count < len(results):
                sys.exit(1)

        execute_all()
        PYEOF
